{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing using spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Introduction of Spacy library\n",
    "- Load english dictionary\n",
    "- Find out stop words\n",
    "- create an nlp object of given document (sentence)\n",
    "- Count frequency of each word using hash values (using count_by(ORTH) and nlp.vocab.strings)\n",
    "- print each word count, using dictionary comprehension\n",
    "- print index of each token\n",
    "- Print various attributes of nlp object (i.e. is_alpha,tok.shape_,is_stop,tok.pos_,tok.tag_) !!!\n",
    "- Lemmatization\n",
    "- Display tree view of words using displacy using displacy.render()\n",
    "- How to get the meaning of any denoted words by nlp using explain(<word>)\n",
    "- How to Find out NER(Named entity Recognition) in given doc\n",
    "- Display Named Entity in doc using displacy.render\n",
    "- Remove stop_words/punctuation using is_stop & is_punct attribute\n",
    "- create a list of words/sentence after removing stop_words then make sentence\n",
    "- Sentence and Word Tokenization\n",
    "- Pipelining:\n",
    "    - Get all the factory pipelining options available\n",
    "    - How to disable preloaded pipeline, that will enahnce the processing time?\n",
    "    - Adding custom pipelines\n",
    "- Reading a file and displaying entity\n",
    "- n-grams (using nltk and sklearn-CountVectorizer())\n",
    "    - bi-grams\n",
    "    - tri-grams\n",
    "    - n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:43:36.034120Z",
     "start_time": "2022-02-04T15:43:36.031091Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:45:27.407598Z",
     "start_time": "2022-02-04T15:45:27.404273Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "from spacy import displacy # used for data visualization\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.attrs import ORTH # to be used for word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:45:29.360013Z",
     "start_time": "2022-02-04T15:45:29.355049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.1'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:45:32.645272Z",
     "start_time": "2022-02-04T15:45:32.093908Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = sp.load(\"en_core_web_sm\") \n",
    "# ref: https://spacy.io/models/en\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To load english model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:46:10.026766Z",
     "start_time": "2022-02-04T15:46:10.023562Z"
    }
   },
   "outputs": [],
   "source": [
    "txt = \"\"\"Commercial writers know that most people don’t want to read 1,000\n",
    "words of closely-spaced text in order to see what they are writing about, so \n",
    "they also like to keep sentences and paragraphs short. \n",
    "They’ll even use lots of sub-headers so you can see what each paragraph is about \n",
    "before you read it. I need 1m dollar\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get all the words from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:46:52.324378Z",
     "start_time": "2022-02-04T15:46:52.285994Z"
    }
   },
   "outputs": [],
   "source": [
    "obj = nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:46:58.046606Z",
     "start_time": "2022-02-04T15:46:58.043771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commercial writers know that most people don’t want to read 1,000\n",
      "words of closely-spaced text in order to see what they are writing about, so \n",
      "they also like to keep sentences and paragraphs short. \n",
      "They’ll even use lots of sub-headers so you can see what each paragraph is about \n",
      "before you read it. I need 1m dollar\n"
     ]
    }
   ],
   "source": [
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:47:40.673493Z",
     "start_time": "2022-02-04T15:47:40.669499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "for w in obj:\n",
    "    print(type(w))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:48:26.189409Z",
     "start_time": "2022-02-04T15:48:26.182863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commercial\n",
      "writers\n",
      "know\n",
      "that\n",
      "most\n",
      "people\n",
      "do\n",
      "n’t\n",
      "want\n",
      "to\n",
      "read\n",
      "1,000\n",
      "\n",
      "\n",
      "words\n",
      "of\n",
      "closely\n",
      "-\n",
      "spaced\n",
      "text\n",
      "in\n",
      "order\n",
      "to\n",
      "see\n",
      "what\n",
      "they\n",
      "are\n",
      "writing\n",
      "about\n",
      ",\n",
      "so\n",
      "\n",
      "\n",
      "they\n",
      "also\n",
      "like\n",
      "to\n",
      "keep\n",
      "sentences\n",
      "and\n",
      "paragraphs\n",
      "short\n",
      ".\n",
      "\n",
      "\n",
      "They\n",
      "’ll\n",
      "even\n",
      "use\n",
      "lots\n",
      "of\n",
      "sub\n",
      "-\n",
      "headers\n",
      "so\n",
      "you\n",
      "can\n",
      "see\n",
      "what\n",
      "each\n",
      "paragraph\n",
      "is\n",
      "about\n",
      "\n",
      "\n",
      "before\n",
      "you\n",
      "read\n",
      "it\n",
      ".\n",
      "I\n",
      "need\n",
      "1\n",
      "m\n",
      "dollar\n"
     ]
    }
   ],
   "source": [
    "for w in obj:\n",
    "    print(w.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:49:23.217093Z",
     "start_time": "2022-02-04T15:49:23.212343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Commercial, False)\n",
      "(writers, False)\n",
      "(know, False)\n",
      "(that, True)\n",
      "(most, True)\n",
      "(people, False)\n",
      "(do, True)\n",
      "(n’t, True)\n",
      "(want, False)\n",
      "(to, True)\n",
      "(read, False)\n",
      "(1,000, False)\n",
      "(\n",
      ", False)\n",
      "(words, False)\n",
      "(of, True)\n",
      "(closely, False)\n",
      "(-, False)\n",
      "(spaced, False)\n",
      "(text, False)\n",
      "(in, True)\n",
      "(order, False)\n",
      "(to, True)\n",
      "(see, True)\n",
      "(what, True)\n",
      "(they, True)\n",
      "(are, True)\n",
      "(writing, False)\n",
      "(about, True)\n",
      "(,, False)\n",
      "(so, True)\n",
      "(\n",
      ", False)\n",
      "(they, True)\n",
      "(also, True)\n",
      "(like, False)\n",
      "(to, True)\n",
      "(keep, True)\n",
      "(sentences, False)\n",
      "(and, True)\n",
      "(paragraphs, False)\n",
      "(short, False)\n",
      "(., False)\n",
      "(\n",
      ", False)\n",
      "(They, True)\n",
      "(’ll, True)\n",
      "(even, True)\n",
      "(use, False)\n",
      "(lots, False)\n",
      "(of, True)\n",
      "(sub, False)\n",
      "(-, False)\n",
      "(headers, False)\n",
      "(so, True)\n",
      "(you, True)\n",
      "(can, True)\n",
      "(see, True)\n",
      "(what, True)\n",
      "(each, True)\n",
      "(paragraph, False)\n",
      "(is, True)\n",
      "(about, True)\n",
      "(\n",
      ", False)\n",
      "(before, True)\n",
      "(you, True)\n",
      "(read, False)\n",
      "(it, True)\n",
      "(., False)\n",
      "(I, True)\n",
      "(need, False)\n",
      "(1, False)\n",
      "(m, False)\n",
      "(dollar, False)\n"
     ]
    }
   ],
   "source": [
    "for w in obj:\n",
    "    print((w,w.is_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:50:21.915882Z",
     "start_time": "2022-02-04T15:50:21.912193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[that, most, do, n’t, to, of, in, to, see, what, they, are, about, so, they, also, to, keep, and, They, ’ll, even, of, so, you, can, see, what, each, is, about, before, you, it, I]\n"
     ]
    }
   ],
   "source": [
    "print([w for w in obj if w.is_stop == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:50:32.754867Z",
     "start_time": "2022-02-04T15:50:32.750233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Commercial, writers, know, people, want, read, 1,000, \n",
      ", words, closely, -, spaced, text, order, writing, ,, \n",
      ", like, sentences, paragraphs, short, ., \n",
      ", use, lots, sub, -, headers, paragraph, \n",
      ", read, ., need, 1, m, dollar]\n"
     ]
    }
   ],
   "source": [
    "print([w for w in obj if w.is_stop == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:50:54.505654Z",
     "start_time": "2022-02-04T15:50:54.501754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '_bulk_merge', '_context', '_get_array_attrs', '_realloc', '_vector', '_vector_norm', 'cats', 'char_span', 'copy', 'count_by', 'doc', 'ents', 'extend_tensor', 'from_array', 'from_bytes', 'from_dict', 'from_disk', 'from_docs', 'get_extension', 'get_lca_matrix', 'has_annotation', 'has_extension', 'has_unknown_spaces', 'has_vector', 'is_nered', 'is_parsed', 'is_sentenced', 'is_tagged', 'lang', 'lang_', 'mem', 'noun_chunks', 'noun_chunks_iterator', 'remove_extension', 'retokenize', 'sentiment', 'sents', 'set_ents', 'set_extension', 'similarity', 'spans', 'tensor', 'text', 'text_with_ws', 'to_array', 'to_bytes', 'to_dict', 'to_disk', 'to_json', 'to_utf8_array', 'user_data', 'user_hooks', 'user_span_hooks', 'user_token_hooks', 'vector', 'vector_norm', 'vocab']\n"
     ]
    }
   ],
   "source": [
    "print(dir(obj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create an nlp object of given document (sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:51:47.439087Z",
     "start_time": "2022-02-04T15:51:47.435767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commercial writers know that most people don’t want to read 1,000\n",
      "words of closely-spaced text in order to see what they are writing about, so \n",
      "they also like to keep sentences and paragraphs short. \n",
      "They’ll even use lots of sub-headers so you can see what each paragraph is about \n",
      "before you read it. I need 1m dollar\n"
     ]
    }
   ],
   "source": [
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:52:06.865646Z",
     "start_time": "2022-02-04T15:52:06.839887Z"
    }
   },
   "outputs": [],
   "source": [
    "w = nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:52:31.662004Z",
     "start_time": "2022-02-04T15:52:31.659060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commercial writers know that most people don’t want to read 1,000\n",
      "words of closely-spaced text in order to see what they are writing about, so \n",
      "they also like to keep sentences and paragraphs short.\n",
      "\n",
      "They’ll even use lots of sub-headers so you can see what each paragraph is about \n",
      "before you read it.\n",
      "I need 1m dollar\n"
     ]
    }
   ],
   "source": [
    "for s in w.sents:\n",
    "    print(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:53:03.966777Z",
     "start_time": "2022-02-04T15:53:03.962172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commercial writers know that most people don’t want to read 1,000\n",
      "words of closely-spaced text in order to see what they are writing about, so \n",
      "they also like to keep sentences and paragraphs short.\n",
      "\n",
      "They’ll even use lots of sub-headers so you can see what each paragraph is about \n",
      "before you read it.\n",
      "I need 1m dollar\n"
     ]
    }
   ],
   "source": [
    "for s in w.sents:\n",
    "    print(s.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:53:15.425856Z",
     "start_time": "2022-02-04T15:53:15.422228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Commercial', 'writers', 'know', 'that', 'most', 'people', 'don’t', 'want', 'to', 'read', '1,000\\nwords', 'of', 'closely-spaced', 'text', 'in', 'order', 'to', 'see', 'what', 'they', 'are', 'writing', 'about,', 'so', '\\nthey', 'also', 'like', 'to', 'keep', 'sentences', 'and', 'paragraphs', 'short.']\n",
      "['\\nThey’ll', 'even', 'use', 'lots', 'of', 'sub-headers', 'so', 'you', 'can', 'see', 'what', 'each', 'paragraph', 'is', 'about', '\\nbefore', 'you', 'read', 'it.']\n",
      "['I', 'need', '1m', 'dollar']\n"
     ]
    }
   ],
   "source": [
    "for s in w.sents:\n",
    "    print(s.text.split(\" \"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to create separate word from senetence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:53:54.818442Z",
     "start_time": "2022-02-04T15:53:54.767496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commercial\n",
      "writers\n",
      "know\n",
      "that\n",
      "most\n",
      "people\n",
      "do\n",
      "n’t\n",
      "want\n",
      "to\n",
      "read\n",
      "1,000\n",
      "\n",
      "\n",
      "words\n",
      "of\n",
      "closely\n",
      "-\n",
      "spaced\n",
      "text\n",
      "in\n",
      "order\n",
      "to\n",
      "see\n",
      "what\n",
      "they\n",
      "are\n",
      "writing\n",
      "about\n",
      ",\n",
      "so\n",
      "\n",
      "\n",
      "they\n",
      "also\n",
      "like\n",
      "to\n",
      "keep\n",
      "sentences\n",
      "and\n",
      "paragraphs\n",
      "short\n",
      ".\n",
      "\n",
      "\n",
      "They\n",
      "’ll\n",
      "even\n",
      "use\n",
      "lots\n",
      "of\n",
      "sub\n",
      "-\n",
      "headers\n",
      "so\n",
      "you\n",
      "can\n",
      "see\n",
      "what\n",
      "each\n",
      "paragraph\n",
      "is\n",
      "about\n",
      "\n",
      "\n",
      "before\n",
      "you\n",
      "read\n",
      "it\n",
      ".\n",
      "I\n",
      "need\n",
      "1\n",
      "m\n",
      "dollar\n"
     ]
    }
   ],
   "source": [
    "for s in w.sents:\n",
    "    w = nlp(s.text)\n",
    "    for word in w:\n",
    "        print(word.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count frequency of each word using hash values (using count_by(ORTH) and nlp.vocab.strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:55:26.908498Z",
     "start_time": "2022-02-04T15:55:26.885341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Commercial writers know that most people don’t want to read 1,000\n",
       "words of closely-spaced text in order to see what they are writing about, so \n",
       "they also like to keep sentences and paragraphs short. \n",
       "They’ll even use lots of sub-headers so you can see what each paragraph is about \n",
       "before you read it. I need 1m dollar"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = nlp(txt)\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:57:35.871323Z",
     "start_time": "2022-02-04T15:57:35.865478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6679199052911211715: 1,\n",
       " 357501887436434592: 1,\n",
       " 7743033266031195906: 1,\n",
       " 4380130941430378203: 1,\n",
       " 11104729984170784471: 1,\n",
       " 7593739049417968140: 1,\n",
       " 2158845516055552166: 1,\n",
       " 16712971838599463365: 1,\n",
       " 7597692042947428029: 1,\n",
       " 3791531372978436496: 3,\n",
       " 11792590063656742891: 2,\n",
       " 18254674181385630108: 1,\n",
       " 962983613142996970: 4,\n",
       " 10289140944597012527: 1,\n",
       " 886050111519832510: 2,\n",
       " 9696970313201087903: 1,\n",
       " 9153284864653046197: 2,\n",
       " 16159022834684645410: 1,\n",
       " 15099781594404091470: 1,\n",
       " 3002984154512732771: 1,\n",
       " 13136985495629980461: 1,\n",
       " 11925638236994514241: 2,\n",
       " 5865838185239622912: 2,\n",
       " 16875582379069451158: 2,\n",
       " 5012629990875267006: 1,\n",
       " 9147119992364589469: 1,\n",
       " 942632335873952620: 2,\n",
       " 2593208677638477497: 1,\n",
       " 9781598966686434415: 2,\n",
       " 12084876542534825196: 1,\n",
       " 18194338103975822726: 1,\n",
       " 9099225972875567996: 1,\n",
       " 5257340109698985342: 1,\n",
       " 2283656566040971221: 1,\n",
       " 12626284911390218812: 1,\n",
       " 3563698965725164461: 1,\n",
       " 12646065887601541794: 2,\n",
       " 14947529218328092544: 1,\n",
       " 17092777669037358890: 1,\n",
       " 17339226045912991082: 1,\n",
       " 6873750497785110593: 1,\n",
       " 17842523177576739921: 1,\n",
       " 144868287865513341: 1,\n",
       " 18375123465971211096: 1,\n",
       " 7624161793554793053: 2,\n",
       " 6635067063807956629: 1,\n",
       " 5379624210385286023: 1,\n",
       " 9194963477161408182: 1,\n",
       " 3411606890003347522: 1,\n",
       " 11320251846592927908: 1,\n",
       " 10239237003504588839: 1,\n",
       " 4690420944186131903: 1,\n",
       " 478886015463313967: 1,\n",
       " 5533571732986600803: 1,\n",
       " 646772771845179972: 1,\n",
       " 5968252327454094987: 1}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = obj.count_by(ORTH)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:58:30.076900Z",
     "start_time": "2022-02-04T15:58:30.071541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Commercial', 1)\n",
      "('writers', 1)\n",
      "('know', 1)\n",
      "('that', 1)\n",
      "('most', 1)\n",
      "('people', 1)\n",
      "('do', 1)\n",
      "('n’t', 1)\n",
      "('want', 1)\n",
      "('to', 3)\n",
      "('read', 2)\n",
      "('1,000', 1)\n",
      "('\\n', 4)\n",
      "('words', 1)\n",
      "('of', 2)\n",
      "('closely', 1)\n",
      "('-', 2)\n",
      "('spaced', 1)\n",
      "('text', 1)\n",
      "('in', 1)\n",
      "('order', 1)\n",
      "('see', 2)\n",
      "('what', 2)\n",
      "('they', 2)\n",
      "('are', 1)\n",
      "('writing', 1)\n",
      "('about', 2)\n",
      "(',', 1)\n",
      "('so', 2)\n",
      "('also', 1)\n",
      "('like', 1)\n",
      "('keep', 1)\n",
      "('sentences', 1)\n",
      "('and', 1)\n",
      "('paragraphs', 1)\n",
      "('short', 1)\n",
      "('.', 2)\n",
      "('They', 1)\n",
      "('’ll', 1)\n",
      "('even', 1)\n",
      "('use', 1)\n",
      "('lots', 1)\n",
      "('sub', 1)\n",
      "('headers', 1)\n",
      "('you', 2)\n",
      "('can', 1)\n",
      "('each', 1)\n",
      "('paragraph', 1)\n",
      "('is', 1)\n",
      "('before', 1)\n",
      "('it', 1)\n",
      "('I', 1)\n",
      "('need', 1)\n",
      "('1', 1)\n",
      "('m', 1)\n",
      "('dollar', 1)\n"
     ]
    }
   ],
   "source": [
    "for k,v in d.items():\n",
    "    print((nlp.vocab.strings[k],v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print each word count, using dictionary comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:59:07.140046Z",
     "start_time": "2022-02-04T15:59:07.135887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Commercial writers know that most people don’t want to read 1,000\\nwords of closely-spaced text in order to see what they are writing about, so \\nthey also like to keep sentences and paragraphs short. \\nThey’ll even use lots of sub-headers so you can see what each paragraph is about \\nbefore you read it. I need 1m dollar'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T15:59:26.986874Z",
     "start_time": "2022-02-04T15:59:26.980405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Commercial': 1,\n",
       " 'writers': 1,\n",
       " 'know': 1,\n",
       " 'that': 1,\n",
       " 'most': 1,\n",
       " 'people': 1,\n",
       " 'don’t': 1,\n",
       " 'want': 1,\n",
       " 'to': 3,\n",
       " 'read': 2,\n",
       " '1,000\\nwords': 1,\n",
       " 'of': 2,\n",
       " 'closely-spaced': 1,\n",
       " 'text': 1,\n",
       " 'in': 2,\n",
       " 'order': 1,\n",
       " 'see': 2,\n",
       " 'what': 2,\n",
       " 'they': 2,\n",
       " 'are': 1,\n",
       " 'writing': 1,\n",
       " 'about,': 1,\n",
       " 'so': 3,\n",
       " '\\nthey': 1,\n",
       " 'also': 1,\n",
       " 'like': 1,\n",
       " 'keep': 1,\n",
       " 'sentences': 1,\n",
       " 'and': 1,\n",
       " 'paragraphs': 1,\n",
       " 'short.': 1,\n",
       " '\\nThey’ll': 1,\n",
       " 'even': 1,\n",
       " 'use': 1,\n",
       " 'lots': 1,\n",
       " 'sub-headers': 1,\n",
       " 'you': 2,\n",
       " 'can': 1,\n",
       " 'each': 1,\n",
       " 'paragraph': 2,\n",
       " 'is': 1,\n",
       " 'about': 2,\n",
       " '\\nbefore': 1,\n",
       " 'it.': 1,\n",
       " 'I': 1,\n",
       " 'need': 1,\n",
       " '1m': 1,\n",
       " 'dollar': 1}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{w:txt.count(w) for w in txt.split(\" \")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print index and offset index of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T16:00:00.179408Z",
     "start_time": "2022-02-04T16:00:00.156814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Commercial writers know that most people don’t want to read 1,000\n",
       "words of closely-spaced text in order to see what they are writing about, so \n",
       "they also like to keep sentences and paragraphs short. \n",
       "They’ll even use lots of sub-headers so you can see what each paragraph is about \n",
       "before you read it. I need 1m dollar"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = nlp(txt)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = index of a word in parent string\n",
    "idx = offset from the parent string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T16:00:36.151497Z",
     "start_time": "2022-02-04T16:00:36.146140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Commercial', 0, 0)\n",
      "('writers', 1, 11)\n",
      "('know', 2, 19)\n",
      "('that', 3, 24)\n",
      "('most', 4, 29)\n",
      "('people', 5, 34)\n",
      "('do', 6, 41)\n",
      "('n’t', 7, 43)\n",
      "('want', 8, 47)\n",
      "('to', 9, 52)\n",
      "('read', 10, 55)\n",
      "('1,000', 11, 60)\n",
      "('\\n', 12, 65)\n",
      "('words', 13, 66)\n",
      "('of', 14, 72)\n",
      "('closely', 15, 75)\n",
      "('-', 16, 82)\n",
      "('spaced', 17, 83)\n",
      "('text', 18, 90)\n",
      "('in', 19, 95)\n",
      "('order', 20, 98)\n",
      "('to', 21, 104)\n",
      "('see', 22, 107)\n",
      "('what', 23, 111)\n",
      "('they', 24, 116)\n",
      "('are', 25, 121)\n",
      "('writing', 26, 125)\n",
      "('about', 27, 133)\n",
      "(',', 28, 138)\n",
      "('so', 29, 140)\n",
      "('\\n', 30, 143)\n",
      "('they', 31, 144)\n",
      "('also', 32, 149)\n",
      "('like', 33, 154)\n",
      "('to', 34, 159)\n",
      "('keep', 35, 162)\n",
      "('sentences', 36, 167)\n",
      "('and', 37, 177)\n",
      "('paragraphs', 38, 181)\n",
      "('short', 39, 192)\n",
      "('.', 40, 197)\n",
      "('\\n', 41, 199)\n",
      "('They', 42, 200)\n",
      "('’ll', 43, 204)\n",
      "('even', 44, 208)\n",
      "('use', 45, 213)\n",
      "('lots', 46, 217)\n",
      "('of', 47, 222)\n",
      "('sub', 48, 225)\n",
      "('-', 49, 228)\n",
      "('headers', 50, 229)\n",
      "('so', 51, 237)\n",
      "('you', 52, 240)\n",
      "('can', 53, 244)\n",
      "('see', 54, 248)\n",
      "('what', 55, 252)\n",
      "('each', 56, 257)\n",
      "('paragraph', 57, 262)\n",
      "('is', 58, 272)\n",
      "('about', 59, 275)\n",
      "('\\n', 60, 281)\n",
      "('before', 61, 282)\n",
      "('you', 62, 289)\n",
      "('read', 63, 293)\n",
      "('it', 64, 298)\n",
      "('.', 65, 300)\n",
      "('I', 66, 302)\n",
      "('need', 67, 304)\n",
      "('1', 68, 309)\n",
      "('m', 69, 310)\n",
      "('dollar', 70, 312)\n"
     ]
    }
   ],
   "source": [
    "for word in w:\n",
    "    print((word.text,word.i,word.idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print various attributes of nlp object (i.e. is_alpha,tok.shape_,is_stop,tok.pos_,tok.tag_) !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T16:05:39.909801Z",
     "start_time": "2022-02-04T16:05:39.903994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Commercial', 16072095006890171862, 'Xxxxx', True, 84, 'ADJ', 10554686591937588953, 'JJ')\n",
      "('writers', 13110060611322374290, 'xxxx', True, 92, 'NOUN', 783433942507015291, 'NNS')\n",
      "('know', 13110060611322374290, 'xxxx', True, 100, 'VERB', 9188597074677201817, 'VBP')\n",
      "('that', 13110060611322374290, 'xxxx', True, 98, 'SCONJ', 1292078113972184607, 'IN')\n",
      "('most', 13110060611322374290, 'xxxx', True, 84, 'ADJ', 14753207560692742245, 'JJS')\n",
      "('people', 13110060611322374290, 'xxxx', True, 92, 'NOUN', 783433942507015291, 'NNS')\n",
      "('do', 4370460163704169311, 'xx', True, 87, 'AUX', 9188597074677201817, 'VBP')\n",
      "('n’t', 6415657131683920182, 'x’x', False, 94, 'PART', 164681854541413346, 'RB')\n",
      "('want', 13110060611322374290, 'xxxx', True, 100, 'VERB', 14200088355797579614, 'VB')\n",
      "('to', 4370460163704169311, 'xx', True, 94, 'PART', 5595707737748328492, 'TO')\n",
      "('read', 13110060611322374290, 'xxxx', True, 100, 'VERB', 14200088355797579614, 'VB')\n",
      "('1,000', 8163372826296935398, 'd,ddd', False, 93, 'NUM', 8427216679587749980, 'CD')\n",
      "('\\n', 962983613142996970, '\\n', False, 103, 'SPACE', 6893682062797376370, '_SP')\n",
      "('words', 13110060611322374290, 'xxxx', True, 92, 'NOUN', 783433942507015291, 'NNS')\n",
      "('of', 4370460163704169311, 'xx', True, 85, 'ADP', 1292078113972184607, 'IN')\n",
      "('closely', 13110060611322374290, 'xxxx', True, 86, 'ADV', 164681854541413346, 'RB')\n",
      "('-', 9153284864653046197, '-', False, 97, 'PUNCT', 8214596291009089021, 'HYPH')\n",
      "('spaced', 13110060611322374290, 'xxxx', True, 100, 'VERB', 3822385049556375858, 'VBN')\n",
      "('text', 13110060611322374290, 'xxxx', True, 92, 'NOUN', 15308085513773655218, 'NN')\n",
      "('in', 4370460163704169311, 'xx', True, 85, 'ADP', 1292078113972184607, 'IN')\n",
      "('order', 13110060611322374290, 'xxxx', True, 92, 'NOUN', 15308085513773655218, 'NN')\n",
      "('to', 4370460163704169311, 'xx', True, 94, 'PART', 5595707737748328492, 'TO')\n",
      "('see', 4088098365541558500, 'xxx', True, 100, 'VERB', 14200088355797579614, 'VB')\n",
      "('what', 13110060611322374290, 'xxxx', True, 95, 'PRON', 4808651922106831370, 'WP')\n",
      "('they', 13110060611322374290, 'xxxx', True, 95, 'PRON', 13656873538139661788, 'PRP')\n",
      "('are', 4088098365541558500, 'xxx', True, 87, 'AUX', 9188597074677201817, 'VBP')\n",
      "('writing', 13110060611322374290, 'xxxx', True, 100, 'VERB', 1534113631682161808, 'VBG')\n",
      "('about', 13110060611322374290, 'xxxx', True, 85, 'ADP', 1292078113972184607, 'IN')\n",
      "(',', 2593208677638477497, ',', False, 97, 'PUNCT', 2593208677638477497, ',')\n",
      "('so', 4370460163704169311, 'xx', True, 89, 'CCONJ', 17571114184892886314, 'CC')\n",
      "('\\n', 962983613142996970, '\\n', False, 103, 'SPACE', 6893682062797376370, '_SP')\n",
      "('they', 13110060611322374290, 'xxxx', True, 95, 'PRON', 13656873538139661788, 'PRP')\n",
      "('also', 13110060611322374290, 'xxxx', True, 86, 'ADV', 164681854541413346, 'RB')\n",
      "('like', 13110060611322374290, 'xxxx', True, 100, 'VERB', 9188597074677201817, 'VBP')\n",
      "('to', 4370460163704169311, 'xx', True, 94, 'PART', 5595707737748328492, 'TO')\n",
      "('keep', 13110060611322374290, 'xxxx', True, 100, 'VERB', 14200088355797579614, 'VB')\n",
      "('sentences', 13110060611322374290, 'xxxx', True, 92, 'NOUN', 783433942507015291, 'NNS')\n",
      "('and', 4088098365541558500, 'xxx', True, 89, 'CCONJ', 17571114184892886314, 'CC')\n",
      "('paragraphs', 13110060611322374290, 'xxxx', True, 92, 'NOUN', 783433942507015291, 'NNS')\n",
      "('short', 13110060611322374290, 'xxxx', True, 84, 'ADJ', 10554686591937588953, 'JJ')\n",
      "('.', 12646065887601541794, '.', False, 97, 'PUNCT', 12646065887601541794, '.')\n",
      "('\\n', 962983613142996970, '\\n', False, 103, 'SPACE', 6893682062797376370, '_SP')\n",
      "('They', 10887629174180191697, 'Xxxx', True, 95, 'PRON', 13656873538139661788, 'PRP')\n",
      "('’ll', 12090792887388573713, '’xx', False, 87, 'AUX', 16235386156175103506, 'MD')\n",
      "('even', 13110060611322374290, 'xxxx', True, 86, 'ADV', 164681854541413346, 'RB')\n",
      "('use', 4088098365541558500, 'xxx', True, 100, 'VERB', 14200088355797579614, 'VB')\n",
      "('lots', 13110060611322374290, 'xxxx', True, 92, 'NOUN', 783433942507015291, 'NNS')\n",
      "('of', 4370460163704169311, 'xx', True, 85, 'ADP', 1292078113972184607, 'IN')\n",
      "('sub', 4088098365541558500, 'xxx', True, 92, 'NOUN', 783433942507015291, 'NNS')\n",
      "('-', 9153284864653046197, '-', False, 92, 'NOUN', 783433942507015291, 'NNS')\n",
      "('headers', 13110060611322374290, 'xxxx', True, 92, 'NOUN', 783433942507015291, 'NNS')\n",
      "('so', 4370460163704169311, 'xx', True, 98, 'SCONJ', 1292078113972184607, 'IN')\n",
      "('you', 4088098365541558500, 'xxx', True, 95, 'PRON', 13656873538139661788, 'PRP')\n",
      "('can', 4088098365541558500, 'xxx', True, 87, 'AUX', 16235386156175103506, 'MD')\n",
      "('see', 4088098365541558500, 'xxx', True, 100, 'VERB', 14200088355797579614, 'VB')\n",
      "('what', 13110060611322374290, 'xxxx', True, 95, 'PRON', 4808651922106831370, 'WP')\n",
      "('each', 13110060611322374290, 'xxxx', True, 90, 'DET', 15267657372422890137, 'DT')\n",
      "('paragraph', 13110060611322374290, 'xxxx', True, 92, 'NOUN', 15308085513773655218, 'NN')\n",
      "('is', 4370460163704169311, 'xx', True, 87, 'AUX', 13927759927860985106, 'VBZ')\n",
      "('about', 13110060611322374290, 'xxxx', True, 85, 'ADP', 1292078113972184607, 'IN')\n",
      "('\\n', 962983613142996970, '\\n', False, 103, 'SPACE', 6893682062797376370, '_SP')\n",
      "('before', 13110060611322374290, 'xxxx', True, 98, 'SCONJ', 1292078113972184607, 'IN')\n",
      "('you', 4088098365541558500, 'xxx', True, 95, 'PRON', 13656873538139661788, 'PRP')\n",
      "('read', 13110060611322374290, 'xxxx', True, 100, 'VERB', 9188597074677201817, 'VBP')\n",
      "('it', 4370460163704169311, 'xx', True, 95, 'PRON', 13656873538139661788, 'PRP')\n",
      "('.', 12646065887601541794, '.', False, 97, 'PUNCT', 12646065887601541794, '.')\n",
      "('I', 101, 'X', True, 95, 'PRON', 13656873538139661788, 'PRP')\n",
      "('need', 13110060611322374290, 'xxxx', True, 100, 'VERB', 9188597074677201817, 'VBP')\n",
      "('1', 8148669997605808657, 'd', False, 93, 'NUM', 8427216679587749980, 'CD')\n",
      "('m', 11123243248953317070, 'x', True, 92, 'NOUN', 15308085513773655218, 'NN')\n",
      "('dollar', 13110060611322374290, 'xxxx', True, 92, 'NOUN', 15308085513773655218, 'NN')\n"
     ]
    }
   ],
   "source": [
    "for word in w:\n",
    "    print((word.text,word.shape,word.shape_,word.is_alpha,word.pos,word.pos_,word.tag,word.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get meaning of POS or TAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T16:06:23.620774Z",
     "start_time": "2022-02-04T16:06:23.616608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ADJ', 'adjective')\n",
      "('NOUN', 'noun')\n",
      "('VERB', 'verb')\n",
      "('SCONJ', 'subordinating conjunction')\n",
      "('ADJ', 'adjective')\n",
      "('NOUN', 'noun')\n",
      "('AUX', 'auxiliary')\n",
      "('PART', 'particle')\n",
      "('VERB', 'verb')\n",
      "('PART', 'particle')\n",
      "('VERB', 'verb')\n",
      "('NUM', 'numeral')\n",
      "('SPACE', 'space')\n",
      "('NOUN', 'noun')\n",
      "('ADP', 'adposition')\n",
      "('ADV', 'adverb')\n",
      "('PUNCT', 'punctuation')\n",
      "('VERB', 'verb')\n",
      "('NOUN', 'noun')\n",
      "('ADP', 'adposition')\n",
      "('NOUN', 'noun')\n",
      "('PART', 'particle')\n",
      "('VERB', 'verb')\n",
      "('PRON', 'pronoun')\n",
      "('PRON', 'pronoun')\n",
      "('AUX', 'auxiliary')\n",
      "('VERB', 'verb')\n",
      "('ADP', 'adposition')\n",
      "('PUNCT', 'punctuation')\n",
      "('CCONJ', 'coordinating conjunction')\n",
      "('SPACE', 'space')\n",
      "('PRON', 'pronoun')\n",
      "('ADV', 'adverb')\n",
      "('VERB', 'verb')\n",
      "('PART', 'particle')\n",
      "('VERB', 'verb')\n",
      "('NOUN', 'noun')\n",
      "('CCONJ', 'coordinating conjunction')\n",
      "('NOUN', 'noun')\n",
      "('ADJ', 'adjective')\n",
      "('PUNCT', 'punctuation')\n",
      "('SPACE', 'space')\n",
      "('PRON', 'pronoun')\n",
      "('AUX', 'auxiliary')\n",
      "('ADV', 'adverb')\n",
      "('VERB', 'verb')\n",
      "('NOUN', 'noun')\n",
      "('ADP', 'adposition')\n",
      "('NOUN', 'noun')\n",
      "('NOUN', 'noun')\n",
      "('NOUN', 'noun')\n",
      "('SCONJ', 'subordinating conjunction')\n",
      "('PRON', 'pronoun')\n",
      "('AUX', 'auxiliary')\n",
      "('VERB', 'verb')\n",
      "('PRON', 'pronoun')\n",
      "('DET', 'determiner')\n",
      "('NOUN', 'noun')\n",
      "('AUX', 'auxiliary')\n",
      "('ADP', 'adposition')\n",
      "('SPACE', 'space')\n",
      "('SCONJ', 'subordinating conjunction')\n",
      "('PRON', 'pronoun')\n",
      "('VERB', 'verb')\n",
      "('PRON', 'pronoun')\n",
      "('PUNCT', 'punctuation')\n",
      "('PRON', 'pronoun')\n",
      "('VERB', 'verb')\n",
      "('NUM', 'numeral')\n",
      "('NOUN', 'noun')\n",
      "('NOUN', 'noun')\n"
     ]
    }
   ],
   "source": [
    "for word in w:\n",
    "    print((word.pos_,sp.explain(word.pos_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T16:06:47.474434Z",
     "start_time": "2022-02-04T16:06:47.467301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ADJ', 'adjective (English), other noun-modifier (Chinese)')\n",
      "('NOUN', 'noun, plural')\n",
      "('VERB', 'verb, non-3rd person singular present')\n",
      "('SCONJ', 'conjunction, subordinating or preposition')\n",
      "('ADJ', 'adjective, superlative')\n",
      "('NOUN', 'noun, plural')\n",
      "('AUX', 'verb, non-3rd person singular present')\n",
      "('PART', 'adverb')\n",
      "('VERB', 'verb, base form')\n",
      "('PART', 'infinitival \"to\"')\n",
      "('VERB', 'verb, base form')\n",
      "('NUM', 'cardinal number')\n",
      "('SPACE', 'whitespace')\n",
      "('NOUN', 'noun, plural')\n",
      "('ADP', 'conjunction, subordinating or preposition')\n",
      "('ADV', 'adverb')\n",
      "('PUNCT', 'punctuation mark, hyphen')\n",
      "('VERB', 'verb, past participle')\n",
      "('NOUN', 'noun, singular or mass')\n",
      "('ADP', 'conjunction, subordinating or preposition')\n",
      "('NOUN', 'noun, singular or mass')\n",
      "('PART', 'infinitival \"to\"')\n",
      "('VERB', 'verb, base form')\n",
      "('PRON', 'wh-pronoun, personal')\n",
      "('PRON', 'pronoun, personal')\n",
      "('AUX', 'verb, non-3rd person singular present')\n",
      "('VERB', 'verb, gerund or present participle')\n",
      "('ADP', 'conjunction, subordinating or preposition')\n",
      "('PUNCT', 'punctuation mark, comma')\n",
      "('CCONJ', 'conjunction, coordinating')\n",
      "('SPACE', 'whitespace')\n",
      "('PRON', 'pronoun, personal')\n",
      "('ADV', 'adverb')\n",
      "('VERB', 'verb, non-3rd person singular present')\n",
      "('PART', 'infinitival \"to\"')\n",
      "('VERB', 'verb, base form')\n",
      "('NOUN', 'noun, plural')\n",
      "('CCONJ', 'conjunction, coordinating')\n",
      "('NOUN', 'noun, plural')\n",
      "('ADJ', 'adjective (English), other noun-modifier (Chinese)')\n",
      "('PUNCT', 'punctuation mark, sentence closer')\n",
      "('SPACE', 'whitespace')\n",
      "('PRON', 'pronoun, personal')\n",
      "('AUX', 'verb, modal auxiliary')\n",
      "('ADV', 'adverb')\n",
      "('VERB', 'verb, base form')\n",
      "('NOUN', 'noun, plural')\n",
      "('ADP', 'conjunction, subordinating or preposition')\n",
      "('NOUN', 'noun, plural')\n",
      "('NOUN', 'noun, plural')\n",
      "('NOUN', 'noun, plural')\n",
      "('SCONJ', 'conjunction, subordinating or preposition')\n",
      "('PRON', 'pronoun, personal')\n",
      "('AUX', 'verb, modal auxiliary')\n",
      "('VERB', 'verb, base form')\n",
      "('PRON', 'wh-pronoun, personal')\n",
      "('DET', 'determiner')\n",
      "('NOUN', 'noun, singular or mass')\n",
      "('AUX', 'verb, 3rd person singular present')\n",
      "('ADP', 'conjunction, subordinating or preposition')\n",
      "('SPACE', 'whitespace')\n",
      "('SCONJ', 'conjunction, subordinating or preposition')\n",
      "('PRON', 'pronoun, personal')\n",
      "('VERB', 'verb, non-3rd person singular present')\n",
      "('PRON', 'pronoun, personal')\n",
      "('PUNCT', 'punctuation mark, sentence closer')\n",
      "('PRON', 'pronoun, personal')\n",
      "('VERB', 'verb, non-3rd person singular present')\n",
      "('NUM', 'cardinal number')\n",
      "('NOUN', 'noun, singular or mass')\n",
      "('NOUN', 'noun, singular or mass')\n"
     ]
    }
   ],
   "source": [
    "for word in w:\n",
    "    print((word.pos_,sp.explain(word.tag_)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
